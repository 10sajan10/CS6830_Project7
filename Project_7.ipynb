{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "218ae9b5-9bcf-4fef-b2a8-812d40af2399",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'zipfileX'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfileX\u001b[39;00m\n\u001b[1;32m     15\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstroke\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Drop 'id' and target column\u001b[39;00m\n\u001b[1;32m     16\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstroke\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'zipfileX'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import (train_test_split,\n",
    "                                     cross_val_score, KFold, GridSearchCV)\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, confusion_matrix)\n",
    "from imutils import paths\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfileX\n",
    "X = df.drop(['id', 'stroke'], axis=1)  # Drop 'id' and target column\n",
    "y = df['stroke']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a1896-ed0e-4c02-8e73-f315f0bb9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/10sajan10/CS6830_Project7/raw/main/sateliteimage.zip\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    print(\"Download successful!\")\n",
    "    \n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "        print(f\"Files extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe9cab-76fc-4fac-99c5-8c4a7cc4cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_stats(image):\n",
    "\n",
    "    B, G, R = cv2.split(image)\n",
    "\n",
    "    mean_R, mean_G, mean_B = np.mean(R), np.mean(G), np.mean(B)\n",
    "    std_R, std_G, std_B = np.std(R), np.std(G), np.std(B)\n",
    "\n",
    "    features = [mean_R, mean_G, mean_B, std_R, std_G, std_B]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0906b82-c553-4b79-8cdd-2f13552f1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = paths.list_images(r'sateliteimage/')\n",
    "data = []\n",
    "labels_str = []\n",
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    features = extract_color_stats(image)\n",
    "    data.append(features)\n",
    "\n",
    "    # extract the class label from the file path and update the labels list\n",
    "    label = imagePath.split(os.path.sep)[-2].split(\"/\")[1]\n",
    "    labels_str.append(label)\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d1b5f-84cf-4c6a-b17e-b2018c0126c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4390d-e540-4fbf-9bd5-ee642d9dec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['mean_R', 'mean_G', 'mean_B', 'std_R', 'std_G', 'std_B'])\n",
    "df['label'] = labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db028804-6e4c-47c6-8176-da03d379bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Plot for mean(R)\n",
    "plt.subplot(3, 2, 1)\n",
    "sns.histplot(data=df, x='mean_R', hue='label', kde=True)\n",
    "plt.title('Distribution of Mean Red (R) Channel')\n",
    "\n",
    "# Plot for std(R)\n",
    "plt.subplot(3, 2, 2)\n",
    "sns.histplot(data=df, x='std_R', hue='label', kde=True)\n",
    "plt.title('Distribution of Std Red (R) Channel')\n",
    "\n",
    "# Plot for mean(G)\n",
    "plt.subplot(3, 2, 3)\n",
    "sns.histplot(data=df, x='mean_G', hue='label', kde=True)\n",
    "plt.title('Distribution of Mean Green (G) Channel')\n",
    "\n",
    "# Plot for std(G)\n",
    "plt.subplot(3, 2, 4)\n",
    "sns.histplot(data=df, x='std_G', hue='label', kde=True)\n",
    "plt.title('Distribution of Std Green (G) Channel')\n",
    "\n",
    "# Plot for mean(B)\n",
    "plt.subplot(3, 2, 5)\n",
    "sns.histplot(data=df, x='mean_B', hue='label', kde=True)\n",
    "plt.title('Distribution of Mean Blue (B) Channel')\n",
    "\n",
    "# Plot for std(B)\n",
    "plt.subplot(3, 2, 6)\n",
    "sns.histplot(data=df, x='std_B', hue='label', kde=True)\n",
    "plt.title('Distribution of Std Blue (B) Channel')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cfdc3-12f8-41c3-887c-01f5fec9e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 12))\n",
    "\n",
    "# Plot for mean_R vs mean_G\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.scatterplot(data=df, x='mean_R', y='mean_G', hue='label')\n",
    "plt.title('Mean Red (R) vs. Mean Green (G)')\n",
    "plt.xlabel('Mean Red (R)')\n",
    "plt.ylabel('Mean Green (G)')\n",
    "\n",
    "# Plot for mean_R vs mean_B\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.scatterplot(data=df, x='mean_R', y='mean_B', hue='label')\n",
    "plt.title('Mean Red (R) vs. Mean Blue (B)')\n",
    "plt.xlabel('Mean Red (R)')\n",
    "plt.ylabel('Mean Blue (B)')\n",
    "\n",
    "# Plot for mean_G vs mean_B\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.scatterplot(data=df, x='mean_G', y='mean_B', hue='label')\n",
    "plt.title('Mean Green (G) vs. Mean Blue (B)')\n",
    "plt.xlabel('Mean Green (G)')\n",
    "plt.ylabel('Mean Blue (B)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9dee6d-3b67-4c4e-adf7-b4f10ea641e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "trainscore = {}\n",
    "test_accuracy = {}\n",
    "test_precision = {}\n",
    "test_recall = {}\n",
    "scaler = StandardScaler()\n",
    "trainX = scaler.fit_transform(trainX)\n",
    "testX = scaler.transform(testX)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42)\n",
    "scores = cross_val_score(log_reg, trainX, trainY, cv=cv)\n",
    "trainscore['Logistic_Regression'] = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be855108-893f-46ff-950e-937d65d332ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(trainX, trainY)\n",
    "predicted_test_labels = log_reg.predict(testX)\n",
    "conf_matrix = confusion_matrix(testY, predicted_test_labels)\n",
    "print(\"Confusion Matrix of Logistic Regression:\")\n",
    "print(conf_matrix)\n",
    "plt.figure(figsize=(8, 6))\n",
    "le\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix of Logistic Regression\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b742a0-d72c-465f-bf96-5687bed0075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy['Logistic_Regression'] = accuracy_score(testY, predicted_test_labels)\n",
    "test_precision['Logistic_Regression'] = precision_score(testY, predicted_test_labels, average='weighted')\n",
    "test_recall['Logistic_Regression'] = recall_score(testY, predicted_test_labels, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797553ad-7033-45ec-9e32-1954648ca282",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state=42)\n",
    "param_grid = [\n",
    "    {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
    "    {'C': [0.1, 1, 10, 100, 1000], 'degree': [2, 3], 'kernel': ['poly']}]\n",
    "grid = GridSearchCV(svc, param_grid, refit=True, verbose=3)\n",
    "grid.fit(trainX, trainY)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "trainscore['SVC'] = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4258c53d-dd14-44ef-b807-01f57649243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = grid.predict(testX)\n",
    "test_accuracy['SVC'] = accuracy_score(testY, predicted_labels)\n",
    "test_precision['SVC'] = precision_score(testY, predicted_labels, average='weighted')\n",
    "test_recall['SVC'] = recall_score(testY, predicted_labels, average='weighted')\n",
    "print(\"Confusion Matrix of SVC:\")\n",
    "conf_matrix=confusion_matrix(testY, predicted_labels)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix of Logistic Regression\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8028a7fb-7627-404a-a708-dbcb046cdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Train Accuracy': trainscore, 'Test Accuracy': test_accuracy, 'Test Precision': test_precision})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3917e604-09e6-4571-8874-7896b9895540",
   "metadata": {},
   "source": [
    "### Obesity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7efb14e1-7ef2-4ef8-a275-02bc2832c3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('diabetes.zip', 'r') as zip:\n",
    "    # extracting all the files to a specific directory\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extractall('')  # Replace 'path/to/directory' with the target path\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e9d392e-df8b-489e-b438-d463aa60ce62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "Precision: 0.75\n",
      "Recall: 0.58\n",
      "F1 Score: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Outcome'], axis=1)  # Drop 'id' and target column\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "logisticRegr = LogisticRegression(multi_class='ovr', max_iter=1000)  # Increased max_iter to allow convergence\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logisticRegr.predict(x_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c18c7e07-4f74-4e30-a806-fa04f4ededc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "Precision: 0.74\n",
      "Recall: 0.60\n",
      "F1 Score: 0.66\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', random_state=0)  # You can change kernel to 'rbf', 'poly', etc.\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_model.predict(x_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fafae-4ace-4bcf-82a5-30f35b97f13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
